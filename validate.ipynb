{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "validate.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULOAPk0-YclS"
      },
      "source": [
        "# Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5f1MHQZWc7S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc1fcd5f-e201-4276-aa88-31026ffa86e0"
      },
      "source": [
        "print(\"Hello there.\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello there.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zi7jFlJ0WjxQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e89932b-eb4a-452d-e885-b9fc1038a2ed"
      },
      "source": [
        "# Colab specific data upload\n",
        "!unzip cran.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  cran.zip\n",
            "replace cran/cran.all.1400? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQS8XEvyyt_7"
      },
      "source": [
        "# Auto re-import .py files\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "# Plotting with plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4iMFcHkUAeA",
        "outputId": "dae6e814-e31e-4872-b3c7-3944669ab963"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pprint\n",
        "\n",
        "from preprocessing import *\n",
        "from synonym_enrich import *\n",
        "from cosine_sim import *\n",
        "from baseline import *\n",
        "from validate import *"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8T8HX9ZIYaAA",
        "outputId": "7ec3fbd2-9ce5-4b86-95b3-06b407baf75e"
      },
      "source": [
        "!pip install --upgrade gensim\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: gensim in /usr/local/lib/python3.7/dist-packages (4.0.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.0.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
            "  warnings.warn(msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzcV5G5DYhdS"
      },
      "source": [
        "# Validation Core"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwTB938tUezs",
        "outputId": "b999d0d8-e6df-46bb-c555-b5333aa52ba7"
      },
      "source": [
        "# Parameters\n",
        "params = {\n",
        "    \"data_parse_fnt\": parseDocs,\n",
        "    \"retrieval_fnt\": read_cran_relevancy,\n",
        "    \"doc_args\": [\"cran/cran.all.1400\",],\n",
        "    \"query_args\": [\"cran/cran.qry\",],\n",
        "    \"retrieval_args\": {\n",
        "        \"path\": \"cran/cranqrel\",\n",
        "        \"relevancy_threshold\": 4,},\n",
        "    \"preprocessings\": [\n",
        "        tokenize_and_clean,\n",
        "        lemmatize,\n",
        "    ],\n",
        "    \"use_tfidf\": True,\n",
        "    \"use_lsi\": False,\n",
        "    \"d\": 5,\n",
        "    \"embedding\": None,\n",
        "    # \"embedding\": Word2Vec.load(\"w2v.model\"),   # <-- Maybe, load model inside validate()?\n",
        "    # \"embedding\": Word2Vec.load(\"d2v.model\"),\n",
        "    \"k\": 10,\n",
        "    \"test_size\": 0.4,\n",
        "}\n",
        "\n",
        "pprint.pprint(validate(**params))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'mAP': 4.233686067019401}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LcpaJWRbRbw"
      },
      "source": [
        "# Other code\n",
        "\n",
        "Just for inspiration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-Tzm1DNbQxc"
      },
      "source": [
        "def compute_average_results(closest_songs, train_index, test_index):\n",
        "    \"\"\"Computes average metrics for a model based on n closest songs for a test set \n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    closest_songs : a list of lists \n",
        "        a list of length equal to the number of songs in a query matrix\n",
        "        each element contain n closest songs from a training collection to that song\n",
        "    train_index : dict {atrist:lits of song indices}\n",
        "        indices of songs in training collection assigned to artists\n",
        "    test_index : dict {atrist:lits of song indices}\n",
        "        indices of songs in test collection assigned to artists\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    average_precision: float \n",
        "        average precision based on all test songs\n",
        "    average_recall: float\n",
        "        average recall based on all test songs\n",
        "    average_accuracy: float\n",
        "        average accuracy based on all test songs\n",
        "    average_error: float\n",
        "        average error based on all test songs\n",
        "    average_f_measure: float\n",
        "        average f_measure based on all test songs\n",
        "    \"\"\"\n",
        "    \n",
        "    precision = recall = accuracy = error = f_measure = n_tests = 0\n",
        "    n = sum([len(x) for x in train_index.values()])\n",
        "    \n",
        "    art_song_pairs = [(k, x) for k,v in test_index.items() for x in v]\n",
        "    for artist, song_idx in art_song_pairs:\n",
        "        if song_idx >= len(closest_songs):\n",
        "            continue\n",
        "            \n",
        "        n_tests += 1\n",
        "        q_result = closest_songs[song_idx]\n",
        "        \n",
        "        other_artists = list(train_index.keys())\n",
        "        other_artists.remove(artist)\n",
        "        tp = sum([x in train_index[artist] for x in q_result])\n",
        "        fp = sum([x not in train_index[artist] for x in q_result])\n",
        "        fn = sum([x not in q_result for x in train_index[artist]])\n",
        "        tn = sum([x not in q_result for a in other_artists for x in train_index[a]])\n",
        "\n",
        "        p = tp / (tp + fp)\n",
        "        r = tp / (tp + fn)\n",
        "        precision += p\n",
        "        recall += r\n",
        "        accuracy += (tp + tn) / n\n",
        "        error += (fp + fn) / n\n",
        "        if p + r > 0:\n",
        "            f_measure += (2 * p * r) / (p + r)\n",
        "    \n",
        "    return precision / n_tests, recall / n_tests, accuracy / n_tests, error / n_tests, f_measure / n_tests"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}