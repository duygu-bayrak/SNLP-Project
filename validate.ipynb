{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "validate.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULOAPk0-YclS"
      },
      "source": [
        "# Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5f1MHQZWc7S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d06b337-3bd4-47a6-95ad-5e02586a5591"
      },
      "source": [
        "print(\"Hello there.\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello there.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zi7jFlJ0WjxQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bace821-5909-49ef-bc01-d9d0fd3fdeda"
      },
      "source": [
        "# Colab specific data upload\n",
        "!unzip cran.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  cran.zip\n",
            "replace cran/cran.all.1400? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQS8XEvyyt_7"
      },
      "source": [
        "# Auto re-import .py files\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "# Plotting with plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4iMFcHkUAeA",
        "outputId": "f7706ca1-ce9b-4f2e-b01d-637624b4cf5f"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "from collections import defaultdict\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from preprocessing import *\n",
        "from synonym_enrich import *\n",
        "from cosine_sim import *"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8T8HX9ZIYaAA",
        "outputId": "72204d78-54c5-4e04-e511-652d6a8a4581"
      },
      "source": [
        "!pip install --upgrade gensim\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: gensim in /usr/local/lib/python3.7/dist-packages (4.0.1)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.0.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
            "  warnings.warn(msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GUAWxEOjJJL"
      },
      "source": [
        "# Code for `base.py`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcKVJyUTjMuZ"
      },
      "source": [
        "def create_term_doc_matrix(base_docs):\n",
        "    \"\"\" Constructs a frequency term-document matrix\n",
        "    \n",
        "    this function takes in a list of documents and returns a term-document matrix\n",
        "    the rows are lemma types, the columns are documents \n",
        "    the rows should be sorted alphabetically\n",
        "    the order of the columns should be preserved as it's given in base_docs\n",
        "    the cell values are a number of times a lemma was seen in a document\n",
        "    the value should be zero, if a lemma is absent from a document\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    base_docs : a list of lists of strings [['a','a','b'], ['a','b','c']]\n",
        "        a list of documents represented as a list of lemmas\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    matrix : numpy array\n",
        "        a matrix where columns are documents and rows are lemma types,\n",
        "        the cells of the matrix contain lemma counts in a document,\n",
        "        the lemmas for rows are sorted alphabetically\n",
        "        for the example above it will be:\n",
        "            np.array([[2,1],\n",
        "                      [1,1],\n",
        "                      [0,1]])\n",
        "        \n",
        "    sorted_vocab : list of strings\n",
        "        a list of all the lemma types used in all documents (the rows of our matrix)\n",
        "        the words should be strings sorted alphabetically\n",
        "        for the example above it should be ['a','b','c']\n",
        "    \"\"\"\n",
        "    sorted_vocab = list({word for doc in base_docs for word in set(doc)})    \n",
        "    sorted_vocab.sort()\n",
        "\n",
        "    freqs = []\n",
        "    for doc in base_docs:\n",
        "        counter = {k: 0 for k in sorted_vocab}\n",
        "        for k, v in Counter(doc).items():\n",
        "            counter[k] = v\n",
        "        freqs.append(list(counter.values()))\n",
        "    \n",
        "    return np.array(freqs, dtype=np.float64).T, sorted_vocab\n",
        "\n",
        "\n",
        "def create_term_doc_matrix_queries(normalized_queries, sorted_vocabulary):\n",
        "    \"\"\" Constructs a frequency term-document matrix for queries\n",
        "    \n",
        "    this function takes in a list of queries and a vocabulary list and returns a term-document matrix\n",
        "    the rows are lemma types as given in vocabulary, the columns are documents\n",
        "    the rows should be in the same order as in vocabulary given\n",
        "    the order of the columns should be preserved as it's given in normalized_queries\n",
        "    the cell values are a number of times a lemma was seen in a document\n",
        "    the value should be zero, if a lemma is absent from a document\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    normalized_queries : a list of lists of strings [['a','a','b','d'], ['a','b','c']]\n",
        "        a list of queries represented as a list of lemmas\n",
        "    sorted_vocabulary : list of strings\n",
        "        a list of all the lemma types used in all training documents (the rows of our matrix)\n",
        "        the words are strings sorted alphabetically\n",
        "        for our example it will be ['a','b','c']\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    query_matrix : numpy array\n",
        "        a matrix where columns are documents in normalized_queries \n",
        "        and rows are lemma types from sorted_vocabulary.\n",
        "        for the example above it will be:\n",
        "            np.array([[2,1],\n",
        "                      [1,1],\n",
        "                      [0,1]])\n",
        "        'd' is not included in the matrix, because it is absent from sorted_vocabulary\n",
        "    \"\"\"\n",
        "    filtered_queries = [list(filter(lambda x: x in sorted_vocabulary, doc)) for doc in normalized_queries]\n",
        "\n",
        "    freqs = []\n",
        "    for song in filtered_queries:\n",
        "        counter = {k: 0 for k in sorted_vocabulary}\n",
        "        for k, v in Counter(song).items():\n",
        "            counter[k] = v\n",
        "        freqs.append(list(counter.values()))\n",
        "    \n",
        "    return np.array(freqs, dtype=np.float64).T\n",
        "\n",
        "\n",
        "def tf_idf(td_matrix):\n",
        "    \"\"\" Weighs a term-document matrix of raw counts with tf-idf scheme\n",
        "    \n",
        "    this function takes in a term-document matrix as a numpy array, \n",
        "    and weights the scores with the tf-idf algorithm described above.\n",
        "    idf values are modified with log_10\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    td_matrix : numpy array \n",
        "        a matrix where columns are songs and \n",
        "        rows are word counts in a song\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    tf_idf_matrix : numpy array \n",
        "        a matrix where columns are songs and \n",
        "        rows are word tf-idf values in a song\n",
        "        \n",
        "    idf_vector : numpy array of shape (vocabulary-size, 1)\n",
        "        a vector of idf values for words in the collection. the shape is (vocabulary-size, 1)\n",
        "        this vector will be used to weight new query documents\n",
        "    \"\"\"\n",
        "    df_vector = np.sum(np.sign(td_matrix), axis=1)[..., np.newaxis]\n",
        "    n = td_matrix.shape[1]\n",
        "    idf_vector = np.log10(n / df_vector)\n",
        "    \n",
        "    return td_matrix * idf_vector, idf_vector\n",
        "\n",
        "\n",
        "def lsi(matrix, d):\n",
        "    \"\"\" Returns truncted SVD components\n",
        "    \n",
        "    this function takes in a term-document matrix, where\n",
        "    values can be both raw frequencies and weighted values (tf_idf, ppmi)\n",
        "    and returns their trunctaded SVD matrices.\n",
        "\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    matrix : numpy array\n",
        "        a numpy array where columns are songs and \n",
        "        rows are lemmas\n",
        "    d : int\n",
        "        a number of features we will be reducing our matrix to\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    DT_d : numpy array\n",
        "        a [d x m], where m is the number of word dimensions in the original matrix, \n",
        "        and d is the number of features we want to keep\n",
        "        this is a matrix that represents documents with values for d hidden topics\n",
        "    transformation_matrix : numpy array \n",
        "        a matrix to transform queries into the same vector space as DT_d\n",
        "        T_dS_d^-, where S_d^- is inverse of S_d\n",
        "    \"\"\"\n",
        "\n",
        "    T, s, DT = np.linalg.svd(matrix)\n",
        "    return DT[:d, :], T[:, :d] @ np.linalg.inv(np.diag(s[:d]))\n",
        "\n",
        "\n",
        "def read_cran_relevancy(path, relevancy_threshold=3):\n",
        "    \"\"\" Loads query relevancy information from the cran dataset.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    path : string\n",
        "        path to the cranqrel file containing space-separated columns:\n",
        "            query_id relevant_document_id relevant_document_number\n",
        "\n",
        "    relevancy_threshold : int\n",
        "        relevant_document_number column values are in 5 classes,\n",
        "        1 - most important, 5 - no relevance\n",
        "        this argument defines up to which relevancy the queries are paired\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    query_results : {qid: list of results sorted by relevancy, then by document id} \n",
        "    \"\"\"\n",
        "\n",
        "    # TODO: Make some sanity check.\n",
        "    # Here, indexes should correspond, since\n",
        "    #  td_docs, sorted_vocab = create_term_doc_matrix(docs)\n",
        "    #  td_queries = create_term_doc_matrix_queries(queries, sorted_vocab)\n",
        "    # so queries are indexed the same way as docs.\n",
        "    # In addition, indexes from create_term_doc_matrix should correpond to\n",
        "    # indexes from cran.all.1400, since documents are indexed one-by-one.\n",
        "\n",
        "    query_results = defaultdict(list)\n",
        "\n",
        "    with open(path) as f:\n",
        "        for line in f.readlines():\n",
        "            qid, docid, relevancy = tuple(line.split())\n",
        "            qid, docid, relevancy = int(qid), int(docid), int(relevancy)\n",
        "            if relevancy <= relevancy_threshold:\n",
        "                query_results[qid].append((docid, relevancy))\n",
        "    \n",
        "    for k, v in query_results.items():\n",
        "        query_results[k] = [docid for (docid, relevancy) in sorted(v, key=lambda x: x[1])]\n",
        "    \n",
        "    return dict(query_results)\n",
        "\n",
        "# read_cran_relevancy(\"cran/cranqrel\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocIeCcvpxEoj"
      },
      "source": [
        "# Code for `validate.py`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUyVj8UCxDvW"
      },
      "source": [
        "def closest_n_documents(matrix_collection, matrix_queries, n):\n",
        "    \"\"\"Finds N closest documents from a training collection to every song in a test collection\n",
        "    \n",
        "    this function takes in original document collection, new document collection,\n",
        "    computes cosine similarity between documents in old and new collection, \n",
        "    and outputs the list of n-closest documents to each new song\n",
        "    when a vector in a query has only zeros, \n",
        "        the closeness to it should be determined by index of a song from a matrix_collection:\n",
        "        the closest document for a zero vector has index 0\n",
        "        the second closest document for a zero vector has index 1 and so on\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    matrix_collection : numpy array\n",
        "        a term-document matrix of songs in training collection\n",
        "        songs are columns\n",
        "    matrix_queries : numpy array\n",
        "        a term-document matrix of query songs\n",
        "        songs are columns\n",
        "    n : int\n",
        "        a number of closest documents to return\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    closest_docs : a list of lists \n",
        "        a list of length equal to the number of songs in a query matrix\n",
        "        each element is, in turn, a list of n imdices of documents in matrix_collection that were closest to the query\n",
        "        for n=2 and query matrix with 3 songs, the out put should look like so [[1,2],[1,2],[1,2]]\n",
        "    \"\"\"\n",
        "    _, n1 = matrix_collection.shape\n",
        "    _, n2 = matrix_queries.shape\n",
        "    \n",
        "    closest_docs = []\n",
        "    for i_test in range(n2):\n",
        "        query = matrix_queries[:, i_test]\n",
        "        \n",
        "        if not np.any(query):\n",
        "            closest_docs.append(list(range(n)))\n",
        "            continue\n",
        "        \n",
        "        cosines = np.zeros(n1)\n",
        "        for i_train in range(n1):\n",
        "            cosines[i_train] = cosine_sim(matrix_collection[:, i_train], query)\n",
        "        top_idxs = cosines.argsort()[-n:][::-1]\n",
        "        closest_docs.append(top_idxs.tolist())\n",
        "\n",
        "    return closest_docs\n",
        "\n",
        "\n",
        "def get_k_relevant(k, query, D):\n",
        "    \"\"\"returns ranked list of top k documents in descending order of their\n",
        "    cosine similarity with the query\n",
        "        \n",
        "    Parameters\n",
        "    ----------\n",
        "    k : int\n",
        "        number of documents to retrieve (top k)\n",
        "    query : numpy.ndarray\n",
        "        vector representation of query whose cosine similarity is to be computed with the corpus\n",
        "    D: list of numpy.ndarray\n",
        "        vector representation of all documents in corpus\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    ranked_sims: list of tuples (cosine similarity, index of document)\n",
        "        list of top k cosine similarities and the corresponding documents (their index) in descending order\n",
        "    \"\"\"\n",
        "      \n",
        "    cosine_sims = []\n",
        "    \n",
        "    for i, d in enumerate(D):\n",
        "        cosine_sims.append((cosine_sim(query, d), i))\n",
        "        \n",
        "    ranked_sims = sorted(cosine_sims, key=lambda x: x[0], reverse=True)\n",
        "    \n",
        "    if k != 0:\n",
        "        # if k=0 retrieve all documents in descending order\n",
        "        ranked_sims = ranked_sims[:k]\n",
        "    \n",
        "    return ranked_sims\n",
        "\n",
        "# Retrieval Metrics,\n",
        "# patched version from https://github.com/lgalke/vec4ir/blob/master/vec4ir/rank_metrics.py\n",
        "\n",
        "def precision(r):\n",
        "    r = np.asarray(r)\n",
        "    if r.size == 0:\n",
        "        return 0\n",
        "    tp = np.count_nonzero(r)\n",
        "    return tp / r.size\n",
        "\n",
        "def recall(r, n_relevant):\n",
        "    return np.count_nonzero(r) / n_relevant\n",
        "\n",
        "def precision_at_k(r, k):\n",
        "    \"\"\"Score is precision @ k\n",
        "\n",
        "    Relevance is binary (nonzero is relevant).\n",
        "\n",
        "    >>> r = [0, 0, 1]\n",
        "    >>> precision_at_k(r, 1)\n",
        "    0.0\n",
        "    >>> precision_at_k(r, 2)\n",
        "    0.0\n",
        "    >>> precision_at_k(r, 3)\n",
        "    0.33333333333333331\n",
        "    >>> precision_at_k(r, 4)\n",
        "    Traceback (most recent call last):\n",
        "        File \"<stdin>\", line 1, in ?\n",
        "    ValueError: Relevance score length < k\n",
        "\n",
        "\n",
        "    Args:\n",
        "        r: Relevance scores (list or numpy) in rank order\n",
        "            (first element is the first item)\n",
        "\n",
        "    Returns:\n",
        "        Precision @ k\n",
        "\n",
        "    Raises:\n",
        "        ValueError: len(r) must be >= k\n",
        "    \"\"\"\n",
        "    r = np.asarray(r)[:k] != 0\n",
        "    if r.size != k:\n",
        "        raise ValueError('Relevance score length < k')\n",
        "    return np.mean(r)\n",
        "\n",
        "def average_precision(r):\n",
        "    \"\"\"Score is average precision (area under PR curve)\n",
        "\n",
        "    Relevance is binary (nonzero is relevant).\n",
        "\n",
        "    >>> r = [1, 1, 0, 1, 0, 1, 0, 0, 0, 1]\n",
        "    >>> delta_r = 1. / sum(r)\n",
        "    >>> sum([sum(r[:x + 1]) / (x + 1.) * delta_r for x, y in enumerate(r) if y])\n",
        "    0.7833333333333333\n",
        "    >>> average_precision(r)\n",
        "    0.78333333333333333\n",
        "    >>> r = [1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0]\n",
        "    >>> average_precision(r)\n",
        "    0.78333333333333333\n",
        "    >>> average_precision([1,1,0,0]) == average_precision([1,1])\n",
        "    True\n",
        "    >>> average_precision([0])\n",
        "    0.0\n",
        "\n",
        "\n",
        "    Args:\n",
        "        r: Relevance scores (list or numpy) in rank order\n",
        "            (first element is the first item)\n",
        "\n",
        "    Returns:\n",
        "        Average precision\n",
        "    \"\"\"\n",
        "    r = np.asarray(r) != 0\n",
        "    out = [precision_at_k(r, k + 1) for k in range(r.size) if r[k]]\n",
        "    if not out:\n",
        "        return 0.0\n",
        "    return np.mean(out)\n",
        "\n",
        "def mean_average_precision(rs):\n",
        "    \"\"\"Score is mean average precision\n",
        "\n",
        "    Relevance is binary (nonzero is relevant).\n",
        "\n",
        "    >>> rs = [[1, 1, 0, 1, 0, 1, 0, 0, 0, 1]]\n",
        "    >>> mean_average_precision(rs)\n",
        "    0.78333333333333333\n",
        "    >>> rs = [[1, 1, 0, 1, 0, 1, 0, 0, 0, 1], [0]]\n",
        "    >>> mean_average_precision(rs)\n",
        "    0.39166666666666666\n",
        "\n",
        "    Args:\n",
        "        rs: Iterator of relevance scores (list or numpy) in rank order\n",
        "            (first element is the first item)\n",
        "\n",
        "    Returns:\n",
        "        Mean average precision\n",
        "    \"\"\"\n",
        "    return np.mean([average_precision(r) for r in rs])\n",
        "\n",
        "\n",
        "def preprocess(docs, preprocessings):\n",
        "    for fnt in preprocessings:\n",
        "        docs = fnt(docs)\n",
        "    return docs\n",
        "\n",
        "def query(qids, queries, sorted_vocab):\n",
        "    \"\"\" Transforms queries given by qids into their matrix representation.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    qids : list of ints\n",
        "        query ids to transform\n",
        "    queries : list of strings\n",
        "        list of query lemmas\n",
        "    sorted_vocab: list of strings\n",
        "        a list of all the lemma types used in all documents (the rows of our matrix)\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    query_matrix : numpy array\n",
        "        a matrix where columns are documents in normalized_queries \n",
        "        and rows are lemma types from sorted_vocabulary.\n",
        "    \"\"\"\n",
        "    # TODO: add embedding option\n",
        "    queries = [queries[i] for i in qids]\n",
        "    return create_term_doc_matrix_queries(queries, sorted_vocab)\n",
        "\n",
        "def evaluate(td_docs, td_queries, qids_train, qids_test, n_relevant):\n",
        "    pass"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzcV5G5DYhdS"
      },
      "source": [
        "# Validation Core"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_n70zt_J9F_7"
      },
      "source": [
        "# Set random seed to make experiments reproducible\n",
        "random.seed(0)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "KwTB938tUezs",
        "outputId": "13feed95-976d-4121-a022-69a297370306"
      },
      "source": [
        "# Parameters\n",
        "data_parse_fnt = parseDocs\n",
        "retrieval_fnt = read_cran_relevancy\n",
        "doc_args = [\"cran/cran.all.1400\",]\n",
        "query_args = [\"cran/cran.qry\",]\n",
        "retrieval_args = [\"cran/cranqrel\",]\n",
        "preprocessings = [\n",
        "    tokenize_and_clean,\n",
        "    lemmatize,\n",
        "]\n",
        "n_relevant = 10\n",
        "test_size = 0.3\n",
        "\n",
        "\n",
        "# Load documents\n",
        "docs = data_parse_fnt(*doc_args)\n",
        "\n",
        "# Load queries\n",
        "queries = data_parse_fnt(*query_args)\n",
        "query_results = retrieval_fnt(*retrieval_args)\n",
        "\n",
        "# Split train, val queries:\n",
        "qids_train, qids_test = train_test_split(list(range(1, len(queries))), test_size=test_size)\n",
        "\n",
        "# Preprocess + make model for documents\n",
        "docs = preprocess(docs, preprocessings)  # list of list of lemmatized tokens\n",
        "td_docs, sorted_vocab = create_term_doc_matrix(docs)\n",
        "queries = preprocess(queries, preprocessings)\n",
        "# td_queries = create_term_doc_matrix_queries(queries, sorted_vocab)\n",
        "\n",
        "# tf-idf optional stuff\n",
        "# tf_idf_docs, idf_vector = tf_idf(td_docs)\n",
        "# tf_idf_queries = td_queries * idf_vector\n",
        "\n",
        "# Dimensionality reduction optional stuff\n",
        "# td_docs_dense, td_docs_transform = lsi(tf_idf_docs, 2)\n",
        "# tf_idf_docs_dense, tf_idf_docs_transform = lsi(tf_idf_docs, 2)\n",
        "# td_queries_dense = td_queries.T.dot(td_docs_transform).T\n",
        "# tf_idf_queries_dense = tf_idf_queries.T.dot(tf_idf_docs_transform).T\n",
        "\n",
        "# TODO: add this to the retrieval process\n",
        "# Output like this: embedding.wv['computer']\n",
        "embedding = Word2Vec.load(\"w2v.model\")\n",
        "\n",
        "# def evaluate(td_docs, td_queries, qids_train, qids_test, n_relevant)\n",
        "\n",
        "results = {}\n",
        "rs = []\n",
        "\n",
        "for qid in qids_test:\n",
        "    ranked_sims = get_k_relevant(n_relevant, query([qid], queries, sorted_vocab), td_docs)\n",
        "    docs_pred = [x[1] for x in ranked_sims]\n",
        "    docs_true = query_results[qid][:n_relevant]\n",
        "    rs.append([int(x[0] == x[1]) for x in zip(docs_pred, docs_true)])\n",
        "\n",
        "results[\"MAP\"] = mean_average_precision(rs)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-5508b1d5948a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mqid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mqids_test\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mranked_sims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_k_relevant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_relevant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mqid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtd_docs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0mdocs_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mranked_sims\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mdocs_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mqid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_relevant\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-4487c818aed0>\u001b[0m in \u001b[0;36mget_k_relevant\u001b[0;34m(k, query, D)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mcosine_sims\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcosine_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mranked_sims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcosine_sims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/cosine_sim.py\u001b[0m in \u001b[0;36mcosine_sim\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \"\"\"\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mcos_sim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcos_sim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: shapes (8543,1) and (1398,) not aligned: 1 (dim 1) != 1398 (dim 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piBXPv1lbyY9"
      },
      "source": [
        "embedding.wv['computer']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LcpaJWRbRbw"
      },
      "source": [
        "# Other code\n",
        "\n",
        "Just for inspiration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-Tzm1DNbQxc"
      },
      "source": [
        "def compute_average_results(closest_songs, train_index, test_index):\n",
        "    \"\"\"Computes average metrics for a model based on n closest songs for a test set \n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    closest_songs : a list of lists \n",
        "        a list of length equal to the number of songs in a query matrix\n",
        "        each element contain n closest songs from a training collection to that song\n",
        "    train_index : dict {atrist:lits of song indices}\n",
        "        indices of songs in training collection assigned to artists\n",
        "    test_index : dict {atrist:lits of song indices}\n",
        "        indices of songs in test collection assigned to artists\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    average_precision: float \n",
        "        average precision based on all test songs\n",
        "    average_recall: float\n",
        "        average recall based on all test songs\n",
        "    average_accuracy: float\n",
        "        average accuracy based on all test songs\n",
        "    average_error: float\n",
        "        average error based on all test songs\n",
        "    average_f_measure: float\n",
        "        average f_measure based on all test songs\n",
        "    \"\"\"\n",
        "    \n",
        "    precision = recall = accuracy = error = f_measure = n_tests = 0\n",
        "    n = sum([len(x) for x in train_index.values()])\n",
        "    \n",
        "    art_song_pairs = [(k, x) for k,v in test_index.items() for x in v]\n",
        "    for artist, song_idx in art_song_pairs:\n",
        "        if song_idx >= len(closest_songs):\n",
        "            continue\n",
        "            \n",
        "        n_tests += 1\n",
        "        q_result = closest_songs[song_idx]\n",
        "        \n",
        "        other_artists = list(train_index.keys())\n",
        "        other_artists.remove(artist)\n",
        "        tp = sum([x in train_index[artist] for x in q_result])\n",
        "        fp = sum([x not in train_index[artist] for x in q_result])\n",
        "        fn = sum([x not in q_result for x in train_index[artist]])\n",
        "        tn = sum([x not in q_result for a in other_artists for x in train_index[a]])\n",
        "\n",
        "        p = tp / (tp + fp)\n",
        "        r = tp / (tp + fn)\n",
        "        precision += p\n",
        "        recall += r\n",
        "        accuracy += (tp + tn) / n\n",
        "        error += (fp + fn) / n\n",
        "        if p + r > 0:\n",
        "            f_measure += (2 * p * r) / (p + r)\n",
        "    \n",
        "    return precision / n_tests, recall / n_tests, accuracy / n_tests, error / n_tests, f_measure / n_tests"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}